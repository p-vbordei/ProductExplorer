{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY is ready\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "\n",
    "from openai.embeddings_utils import get_embedding\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "# from sqlalchemy import create_engine\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if os.getenv(\"OPENAI_API_KEY\") is not None:\n",
    "    print (\"OPENAI_API_KEY is ready\")\n",
    "else:\n",
    "    print (\"OPENAI_API_KEY environment variable not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obiectiv Fisier\n",
    "- identific topics, apoi clusterizez si denumesc din nou, daca e nevoie\n",
    "- identific atribute asociate cu topics, apoi le clusterizez si denumesc din nou\n",
    "- fiecare topic si atribut trebuie sa aibe asociate rating-ul, ID-ul review-ului si asin-ul, sentimentele asociate.\n",
    "- plec la drum cu un fisier de reivews redus la minimul necesar. Acelasi fisier de reviews data va fi extins (exploded) astfel incat atributele sa fie specifice unei baze de date:\n",
    "\n",
    "\"Attribute\" (exemplu: when)\n",
    "si value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_reviews_path = '/Users/vladbordei/Documents/Development/ProductExplorer/data/interim/reviews_df_interim.csv'\n",
    "reviews = pd.read_csv(interim_reviews_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.drop(columns = [ 'Verified', 'Helpful', 'Title', 'review','Videos','Variation', 'Style', 'num_tokens', 'review_num_tokens','initial_response', 'interim_response', 'eval_response'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cols = ['Review Summary', 'Topics',\n",
    "       'Buyer Motivation', 'Customer Expectations', 'How the product is used',\n",
    "       'Where the product is used', 'User Description', 'Packaging', 'Season',\n",
    "       'When the product is used']\n",
    "for col in data_cols:\n",
    "    reviews[col] = reviews[col].fillna('')\n",
    "    reviews[col] = reviews[col].apply(lambda x: x.replace('\\n', ' '))\n",
    "    reviews[col] = reviews[col].apply(lambda x: x.replace('unknown', ''))\n",
    "    reviews[col] = reviews[col].apply(lambda x: x.replace('not mentioned', ''))\n",
    "    reviews[col] = reviews[col].apply(lambda x: x.replace('Not mentioned', ' '))\n",
    "    reviews[col] = reviews[col].apply(lambda x: x.replace('Unknown', ' '))\n",
    "    reviews[col] = reviews[col].apply(lambda x: x.replace('not specified', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_pivot = ['Review Summary', 'Topics', 'Buyer Motivation', 'Customer Expectations', \n",
    "                    'How the product is used', 'Where the product is used', \n",
    "                    'User Description', 'Packaging', 'Season', 'When the product is used']\n",
    "\n",
    "# assume 'df' is your DataFrame\n",
    "df_melted = reviews.melt(id_vars=[col for col in reviews.columns if col not in columns_to_pivot], \n",
    "                    value_vars=columns_to_pivot, \n",
    "                    var_name='Attribute', \n",
    "                    value_name='Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f6/0jn5yf2x1b319g8j96pnjbwh0000gn/T/ipykernel_72051/2895921110.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_melted['Value'].replace([np.nan, '',' ', 'NA', 'N/A', 'missing', 'NaN', 'unknown', 'Unknown', ['Unknown']], 'unknown', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_melted['Value'].replace([np.nan, '',' ', 'NA', 'N/A', 'missing', 'NaN', 'unknown', 'Unknown', ['Unknown']], 'unknown', inplace=True)\n",
    "df_melted = df_melted[df_melted['Value'] != 'unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Buyer Motivation',\n",
       " 'Customer Expectations',\n",
       " 'How the product is used',\n",
       " 'Packaging',\n",
       " 'Review Summary',\n",
       " 'Season',\n",
       " 'Topics',\n",
       " 'User Description',\n",
       " 'When the product is used',\n",
       " 'Where the product is used'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df_melted['Attribute'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_melted[df_melted['Attribute'] ==  'Topics'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'assembly - easy, cordless drill - recommended, support brackets - missing holes',\n",
       " 'assembly - easy, sturdiness - very sturdy',\n",
       " 'assembly - relatively easy, protective plastic - time-consuming to remove, scratches and dents in metal',\n",
       " 'assembly - simple and quick, packaging - well-packaged with clear instructions, durability - expected to last for many years',\n",
       " 'assembly - straightforward, ease of use - intuitive',\n",
       " 'assembly - struggled for over 2 hours',\n",
       " 'assembly - takes about 30 minutes, color options - could be improved',\n",
       " 'assembly - time-consuming, rusting bolts, stability - needs additional support',\n",
       " 'back support - helps tremendously',\n",
       " 'build quality - well built, ease of assembly - easy to put together, plant variety - looking forward to growing many different plants, location - needed something close to the house, gardening with granddaughter - growing crops with 8-year-old granddaughter',\n",
       " 'build time - took a bit of time, appearance - looks good, durability - holding up well, price - much cheaper than similar brands',\n",
       " 'design - square design, fit - fits perfectly next to garden shed and flush against the wall, recommendation - would recommend to anyone who likes to garden, height - good height, less bending while gardening',\n",
       " 'durability - survived hurricane winds',\n",
       " 'durability - very durable, size - strong and large',\n",
       " 'gardening - deep enough for roots to grow, small animals - keeps them out, assembly - easy but time consuming',\n",
       " 'included gloves - nice touch',\n",
       " 'material - super thin',\n",
       " 'materials - flimsy, assembly - difficult, assembly time - too long, durability - poor, future use - dirt and plants, repurchase - no',\n",
       " 'price - fair, size - good, paint protecting - missing, durability - expected to last, rust - can be treated, rubber edging - needed, height - perfect for gardening, unwanted animals - kept out',\n",
       " 'price - too high',\n",
       " 'quality - good, setup - easy',\n",
       " 'raised bed - easy setup, wood grain look - attractive, price - reasonable, sturdy - well-built',\n",
       " 'raised bed gardens - nice appearance, raised bed gardens - easy to assemble, raised bed gardens - clear instructions',\n",
       " 'set up - 30 minutes',\n",
       " 'setup - easy, appearance - awesome',\n",
       " 'setup - took a few mins, measurements - correct',\n",
       " 'size - good, sturdiness - sturdy',\n",
       " 'sturdiness - good, soil - works well, future plans - planting veggies, future plans - ordering more',\n",
       " 'vegetables - lots of rows'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df['Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_clustering_script(database = 'postgresql://postgres:mysecretpassword@localhost/postgres'):\n",
    "    load_dotenv()\n",
    "    OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "    if os.getenv(\"OPENAI_API_KEY\") is not None:\n",
    "        print (\"OPENAI_API_KEY is ready\")\n",
    "    else:\n",
    "        print (\"OPENAI_API_KEY environment variable not found\")\n",
    "\n",
    "    engine = create_engine(database)\n",
    "\n",
    "    embedding_model = \"text-embedding-ada-002\"\n",
    "    embedding_encoding = \"cl100k_base\"  # this the encoding for text-embedding-ada-002\n",
    "    max_tokens = 8000  # the maximum for text-embedding-ada-002 is 8191\n",
    "    encoding = tiktoken.get_encoding(embedding_encoding)\n",
    "        \n",
    "\n",
    "    def get_text_from_embedding(embedding):\n",
    "        return openai.Embedding.retrieve(embedding, model=\"text-embedding-ada-002\")[\"data\"][0][\"text\"]\n",
    "\n",
    "    def get_type_categories(engine=engine, data_table='weighted_trait_graph'):\n",
    "        query = f\"\"\"\n",
    "            SELECT DISTINCT type FROM {data_table};\n",
    "            \"\"\"\n",
    "        type_list = pd.read_sql_query(query, engine)\n",
    "        return type_list\n",
    "\n",
    "    def get_type_data(type, engine=engine, data_table='weighted_trait_graph'):\n",
    "        query = f\"\"\"\n",
    "            SELECT DISTINCT data_label FROM {data_table} WHERE type = '{type}';\n",
    "            \"\"\"\n",
    "        selected_data = pd.read_sql_query(query, engine)\n",
    "        return selected_data\n",
    "\n",
    "    def write_cluster_labels(df, type, engine=engine, data_table='weighted_trait_graph'):\n",
    "        with engine.connect() as con:\n",
    "            # Add cluster_label column if it doesn't exist\n",
    "            con.execute(f\"ALTER TABLE {data_table} ADD COLUMN IF NOT EXISTS cluster_label VARCHAR;\")\n",
    "            \n",
    "            for index, row in df.iterrows():\n",
    "                data_label_val = row['data_label']\n",
    "                cluster_label_val = row['cluster_label']\n",
    "        \n",
    "                query = f\"\"\"\n",
    "                    UPDATE {data_table}\n",
    "                    SET cluster_label = '{cluster_label_val}'\n",
    "                    WHERE type = '{type}'\n",
    "                        AND data_label = '{data_label_val}';\n",
    "                    \"\"\"\n",
    "        \n",
    "                con.execute(query)\n",
    "\n",
    "    def fit_clusters(df, n_clusters = 7, embedding_model = embedding_model, max_tokens = max_tokens):\n",
    "\n",
    "        # omit reviews that are too long to embed\n",
    "        df[\"n_tokens\"] = df['data_label'].apply(lambda x: len(encoding.encode(x)))\n",
    "        df = df[df.n_tokens <= max_tokens]\n",
    "\n",
    "        # Get embeddings\n",
    "        df[\"embedding\"] = df['data_label'].apply(lambda x: get_embedding(x, engine=embedding_model))\n",
    "        df[\"embedding\"] = df[\"embedding\"].apply(np.array)  # convert string to numpy array\n",
    "        matrix = np.vstack(df.embedding.values)\n",
    "\n",
    "        # Fit clusters\n",
    "        n_clusters = n_clusters  # Adjust as needed\n",
    "        clustering = AgglomerativeClustering(n_clusters=n_clusters)\n",
    "        labels = clustering.fit_predict(matrix)\n",
    "\n",
    "        # Add cluster labels to dataframe and create clusters dictionary\n",
    "        df[\"cluster\"] = labels\n",
    "        clusters_dict = {}\n",
    "        for i in range(n_clusters):\n",
    "            clusters_dict[i] = df[df.cluster == i].data_label.values.tolist()\n",
    "\n",
    "        return df, clusters_dict\n",
    "\n",
    "    # %%\n",
    "    def get_chatbot_trait_labels(clusters_dict, temperature=0.2, api_key=OPENAI_API_KEY):\n",
    "        \n",
    "        User_Prompt_1 = \"\"\"\n",
    "        I have a list of phrases, each related to a specific theme. Provide a single label for the theme represented in the list.\n",
    "        List of phrases: {99: ['improved magnet pushability', ' improved magnet strength and functionality', 'improved magnet strength and quality']}\n",
    "        \"\"\"\n",
    "\n",
    "        AI_Prompt_1 = \"\"\"\n",
    "        Magnet Strength and Functionality\n",
    "        \"\"\"\n",
    "\n",
    "        chatbot_responses = {}\n",
    "\n",
    "        for key, data_list in clusters_dict.items():\n",
    "            User_Prompt_2 = f\"List of phrases: {{ {key}: {data_list} }}\"\n",
    "\n",
    "            # Send the prompt to the chatbot and get the response\n",
    "            response = openai.ChatCompletion.create(\n",
    "                        model=\"gpt-3.5-turbo\",\n",
    "                        messages=[\n",
    "                            {\"role\": \"user\", \"content\": User_Prompt_1},\n",
    "                            {\"role\": \"assistant\", \"content\": AI_Prompt_1},\n",
    "                            {\"role\": \"user\", \"content\": User_Prompt_2} ],\n",
    "                        temperature=temperature,\n",
    "                        api_key=api_key\n",
    "            )\n",
    "        \n",
    "            # Process the response and store in the dictionary\n",
    "            chatbot_responses[key] = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "            print(chatbot_responses[key])\n",
    "        \n",
    "        return chatbot_responses\n",
    "\n",
    "    #%%\n",
    "    types = get_type_categories(engine=engine, data_table='weighted_trait_graph')\n",
    "    types_list = types['type'].tolist()\n",
    "    for type in types_list:\n",
    "        df = get_type_data(type = type, data_table = 'weighted_trait_graph')\n",
    "        df, clusters_dict = fit_clusters(n_clusters = 7, df = df)\n",
    "        trait_labels = get_chatbot_trait_labels(clusters_dict,temperature=0.2)\n",
    "        df['cluster_label'] = df['cluster'].map(trait_labels)\n",
    "        write_cluster_labels(df, type = type, data_table = 'weighted_trait_graph' )\n",
    "        write_cluster_labels(df, type = type, data_table = 'weighted_trait_heatmap' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oaie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
